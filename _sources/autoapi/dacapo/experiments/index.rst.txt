:py:mod:`dacapo.experiments`
============================

.. py:module:: dacapo.experiments


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   architectures/index.rst
   arraytypes/index.rst
   datasplits/index.rst
   starts/index.rst
   tasks/index.rst
   trainers/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   model/index.rst
   run/index.rst
   run_config/index.rst
   training_iteration_stats/index.rst
   training_stats/index.rst
   validation_iteration_scores/index.rst
   validation_scores/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   dacapo.experiments.Model
   dacapo.experiments.RunConfig
   dacapo.experiments.TrainingIterationStats
   dacapo.experiments.TrainingStats
   dacapo.experiments.ValidationIterationScores
   dacapo.experiments.ValidationScores




.. py:class:: Model(architecture: dacapo.experiments.architectures.architecture.Architecture, prediction_head: torch.nn.Module, eval_activation: torch.nn.Module | None = None)




   A trainable DaCapo model. Consists of an ``Architecture`` and a
   prediction head. Models are generated by ``Predictor``s.

   May include an optional eval_activation that is only executed when the model
   is in eval mode. This is particularly useful if you want to train with something
   like BCELossWithLogits, since you want to avoid applying softmax while training,
   but apply it during evaluation.

   .. py:attribute:: num_out_channels
      :type: int

      

   .. py:attribute:: num_in_channels
      :type: int

      

   .. py:method:: forward(x)


   .. py:method:: compute_output_shape(input_shape: funlib.geometry.Coordinate) -> Tuple[int, funlib.geometry.Coordinate]

      Compute the spatial shape (i.e., not accounting for channels and
      batch dimensions) of this model, when fed a tensor of the given spatial
      shape as input.


   .. py:method:: scale(voxel_size: funlib.geometry.Coordinate) -> funlib.geometry.Coordinate



.. py:class:: RunConfig


   A class to represent a configuration of a run that helps to structure all the tasks,
   architecture, training, and datasplit configurations.

   ...

   Attributes:
   -----------
   task_config: `TaskConfig`
       A config defining the Task to run that includes deciding the output of the model and
       different methods to achieve the goal.

   architecture_config: `ArchitectureConfig`
        A config that defines the backbone architecture of the model. It impacts the model's
        performance significantly.

   trainer_config: `TrainerConfig`
       Defines how batches are generated and passed for training the model along with defining
       configurations like batch size, learning rate, number of cpu workers and snapshot logging.

   datasplit_config: `DataSplitConfig`
       Configures the data available for the model during training or validation phases.

   name: str
       A unique name for this run to distinguish it.

   repetition: int
       The repetition number of this run.

   num_iterations: int
       The total number of iterations to train for during this run.

   validation_interval: int
       Specifies how often to perform validation during the run. It defaults to 1000.

   start_config : `Optional[StartConfig]`
       A starting point for continued training. It is optional and can be left out.

   .. py:attribute:: task_config
      :type: dacapo.experiments.tasks.TaskConfig

      

   .. py:attribute:: architecture_config
      :type: dacapo.experiments.architectures.ArchitectureConfig

      

   .. py:attribute:: trainer_config
      :type: dacapo.experiments.trainers.TrainerConfig

      

   .. py:attribute:: datasplit_config
      :type: dacapo.experiments.datasplits.DataSplitConfig

      

   .. py:attribute:: name
      :type: str

      

   .. py:attribute:: repetition
      :type: int

      

   .. py:attribute:: num_iterations
      :type: int

      

   .. py:attribute:: validation_interval
      :type: int

      

   .. py:attribute:: start_config
      :type: Optional[dacapo.experiments.starts.StartConfig]

      


.. py:class:: TrainingIterationStats


   A class to represent the training iteration statistics.

   .. attribute:: iteration

      The iteration that produced these stats.

      :type: int

   .. attribute:: loss

      The loss value of this iteration.

      :type: float

   .. attribute:: time

      The time it took to process this iteration.

      :type: float

   .. py:attribute:: iteration
      :type: int

      

   .. py:attribute:: loss
      :type: float

      

   .. py:attribute:: time
      :type: float

      


.. py:class:: TrainingStats


   A class used to represent Training Statistics.

   .. attribute:: iteration_stats

      List[TrainingIterationStats]
      an ordered list of training stats.

   .. method:: add_iteration_stats(iteration_stats

      TrainingIterationStats) -> None:
      Add a new set of iterations stats to the existing list of iteration
      stats.

   .. method:: delete_after(iteration

      int) -> None:
      Deletes training stats after a specified iteration number.

   .. method:: trained_until() -> int

      
      Gets the number of iterations that the model has been trained for.

   .. method:: to_xarray() -> xr.DataArray

      
      Converts the iteration statistics to a xarray data array.
      

   .. py:attribute:: iteration_stats
      :type: List[dacapo.experiments.training_iteration_stats.TrainingIterationStats]

      

   .. py:method:: add_iteration_stats(iteration_stats: dacapo.experiments.training_iteration_stats.TrainingIterationStats) -> None

      Add a new iteration stats to the current iteration stats.

      :param iteration_stats: a new iteration stats object.
      :type iteration_stats: TrainingIterationStats

      :raises assert: if the new iteration stats do not follow the order of existing iteration stats.


   .. py:method:: delete_after(iteration: int) -> None

      Deletes training stats after a specified iteration.

      :param iteration: the iteration after which the stats are to be deleted.
      :type iteration: int


   .. py:method:: trained_until() -> int

      The number of iterations trained for (the maximum iteration plus one).
      Returns zero if no iterations trained yet.

      :returns: number of iterations that the model has been trained for.
      :rtype: int


   .. py:method:: to_xarray() -> xarray.DataArray

      Converts the iteration stats to a data array format easily manipulatable.

      :returns: xarray DataArray of iteration losses.
      :rtype: xr.DataArray



.. py:class:: ValidationIterationScores


   A class used to represent the validation iteration scores in an organized structure.

   .. attribute:: iteration

      The iteration associated with these validation scores.

      :type: int

   .. attribute:: scores

      A list of scores per dataset, post processor

      :type: List[List[List[float]]]

   .. attribute:: parameters, and evaluation criterion.

      

   .. py:attribute:: iteration
      :type: int

      

   .. py:attribute:: scores
      :type: List[List[List[float]]]

      


.. py:class:: ValidationScores


   .. py:property:: criteria
      :type: List[str]


   .. py:property:: parameter_names
      :type: List[str]


   .. py:attribute:: parameters
      :type: List[dacapo.experiments.tasks.post_processors.PostProcessorParameters]

      

   .. py:attribute:: datasets
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      

   .. py:attribute:: evaluation_scores
      :type: dacapo.experiments.tasks.evaluators.EvaluationScores

      

   .. py:attribute:: scores
      :type: List[dacapo.experiments.validation_iteration_scores.ValidationIterationScores]

      

   .. py:method:: subscores(iteration_scores: List[dacapo.experiments.validation_iteration_scores.ValidationIterationScores]) -> ValidationScores


   .. py:method:: add_iteration_scores(iteration_scores: dacapo.experiments.validation_iteration_scores.ValidationIterationScores) -> None


   .. py:method:: delete_after(iteration: int) -> None


   .. py:method:: validated_until() -> int

      The number of iterations validated for (the maximum iteration plus
      one).


   .. py:method:: compare(existing_iteration_scores: List[dacapo.experiments.validation_iteration_scores.ValidationIterationScores]) -> Tuple[bool, int]

      Compares iteration stats provided from elsewhere to scores we have saved locally.
      Local scores take priority. If local scores are at a lower iteration than the
      existing ones, delete the existing ones and replace with local.
      If local iteration > existing iteration, just update existing scores with the last
      overhanging local scores.


   .. py:method:: to_xarray() -> xarray.DataArray


   .. py:method:: get_best(data: xarray.DataArray, dim: str) -> Tuple[xarray.DataArray, xarray.DataArray]

      Compute the Best scores along dimension "dim" per criterion.
      Returns both the index associated with the best value, and the
      best value in two seperate arrays.



