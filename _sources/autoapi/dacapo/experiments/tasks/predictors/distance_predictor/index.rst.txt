:py:mod:`dacapo.experiments.tasks.predictors.distance_predictor`
================================================================

.. py:module:: dacapo.experiments.tasks.predictors.distance_predictor


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   dacapo.experiments.tasks.predictors.distance_predictor.DistancePredictor




Attributes
~~~~~~~~~~

.. autoapisummary::

   dacapo.experiments.tasks.predictors.distance_predictor.logger


.. py:data:: logger

   

.. py:class:: DistancePredictor(channels: List[str], scale_factor: float, mask_distances: bool, clipmin: float = 0.05, clipmax: float = 0.95)




   Predict signed distances for a binary segmentation task.
   Distances deep within background are pushed to -inf, distances deep within
   the foreground object are pushed to inf. After distances have been
   calculated they are passed through a tanh so that distances saturate at +-1.
   Multiple classes can be predicted via multiple distance channels. The names
   of each class that is being segmented can be passed in as a list of strings
   in the channels argument.

   .. py:property:: embedding_dims


   .. py:property:: output_array_type


   .. py:method:: create_model(architecture)

      Given a training architecture, create a model for this predictor.
      This is usually done by appending extra layers to the output of the
      architecture to get the output tensor of the architecture into the
      right shape for this predictor.


   .. py:method:: create_target(gt)

      Create the target array for training, given a ground-truth array.

      In general, the target is different from the ground-truth.

      The target is the array that is passed to the loss, and hence directly
      compared to the prediction (i.e., the output of the model). Depending
      on the predictor, the target can therefore be different from the
      ground-truth (e.g., an instance segmentation ground-truth would have to
      be converted into boundaries, if the model is predicting boundaries).

      By default, it is assumed that the spatial dimensions of ground-truth
      and target are the same.

      If your predictor needs more ground-truth context to create a target
      (e.g., because it predicts the distance to a boundary, up to a certain
      threshold), you can request a larger ground-truth region. See method
      ``gt_region_for_roi``.


   .. py:method:: create_weight(gt, target, mask, moving_class_counts=None)

      Create the weight array for training, given a ground-truth and
      associated target array.


   .. py:method:: create_distance_mask(distances: numpy.ndarray, mask: numpy.ndarray, voxel_size: funlib.geometry.Coordinate, normalize=None, normalize_args=None)


   .. py:method:: process(labels: numpy.ndarray, voxel_size: funlib.geometry.Coordinate, normalize=None, normalize_args=None)


   .. py:method:: gt_region_for_roi(target_spec)

      Report how much spatial context this predictor needs to generate a
      target for the given ROI. By default, uses the same ROI.

      Overwrite this method to request ground-truth in a larger ROI, as
      needed.


   .. py:method:: padding(gt_voxel_size: funlib.geometry.Coordinate) -> funlib.geometry.Coordinate



