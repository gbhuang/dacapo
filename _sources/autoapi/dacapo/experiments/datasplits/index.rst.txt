:py:mod:`dacapo.experiments.datasplits`
=======================================

.. py:module:: dacapo.experiments.datasplits


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   datasets/index.rst
   keys/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   datasplit/index.rst
   datasplit_config/index.rst
   datasplit_generator/index.rst
   dummy_datasplit/index.rst
   dummy_datasplit_config/index.rst
   train_validate_datasplit/index.rst
   train_validate_datasplit_config/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   dacapo.experiments.datasplits.DataSplit
   dacapo.experiments.datasplits.DataSplitConfig
   dacapo.experiments.datasplits.DummyDataSplit
   dacapo.experiments.datasplits.DummyDataSplitConfig
   dacapo.experiments.datasplits.TrainValidateDataSplit
   dacapo.experiments.datasplits.TrainValidateDataSplitConfig
   dacapo.experiments.datasplits.DataSplitGenerator




.. py:class:: DataSplit




   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:attribute:: train
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      

   .. py:attribute:: validate
      :type: Optional[List[dacapo.experiments.datasplits.datasets.Dataset]]

      


.. py:class:: DataSplitConfig


   A class used to create a DataSplit configuration object.

   .. attribute:: name

      A name for the datasplit. This name will be saved so it can be found
      and reused easily. It is recommended to keep it short and avoid special
      characters.

      :type: str

   .. method:: verify() -> Tuple[bool, str]:

      Validates if it is a valid data split configuration.


   .. py:attribute:: name
      :type: str

      

   .. py:method:: verify() -> Tuple[bool, str]

      Validates if the current configuration is a valid data split configuration.

      :returns: True if the configuration is valid,
                False otherwise along with respective validation error message.
      :rtype: Tuple[bool, str]



.. py:class:: DummyDataSplit(datasplit_config)




   A class for creating a simple train dataset and no validation dataset.

   It is derived from `DataSplit` class.

   ...
   .. attribute:: train

      The list containing training datasets. In this class, it contains only one dataset for training.

      :type: list

   .. attribute:: validate

      The list containing validation datasets. In this class, it is an empty list as no validation dataset is set.

      :type: list

   .. method:: __init__(self, datasplit_config):

      The constructor for DummyDataSplit class. It initialises a list with training datasets according to the input configuration.


   .. py:attribute:: train
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      

   .. py:attribute:: validate
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      


.. py:class:: DummyDataSplitConfig




   A simple class representing config for Dummy DataSplit.

   This class is derived from 'DataSplitConfig' and is initialized with
   'DatasetConfig' for training dataset.

   .. attribute:: datasplit_type

      Class of dummy data split functionality.

   .. attribute:: train_config

      Config for the training dataset. Defaults to DummyDatasetConfig.

   .. py:attribute:: datasplit_type

      

   .. py:attribute:: train_config
      :type: dacapo.experiments.datasplits.datasets.DatasetConfig

      

   .. py:method:: verify() -> Tuple[bool, str]

      A method for verification. This method always return 'False' plus
      a string indicating the condition.

      :returns: A tuple contains a boolean 'False' and a string.
      :rtype: Tuple[bool, str]



.. py:class:: TrainValidateDataSplit(datasplit_config)




   Helper class that provides a standard way to create an ABC using
   inheritance.

   .. py:attribute:: train
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      

   .. py:attribute:: validate
      :type: List[dacapo.experiments.datasplits.datasets.Dataset]

      


.. py:class:: TrainValidateDataSplitConfig




   This is the standard Train/Validate DataSplit config.

   .. py:attribute:: datasplit_type

      

   .. py:attribute:: train_configs
      :type: List[dacapo.experiments.datasplits.datasets.DatasetConfig]

      

   .. py:attribute:: validate_configs
      :type: List[dacapo.experiments.datasplits.datasets.DatasetConfig]

      


.. py:class:: DataSplitGenerator(name: str, datasets: List[DatasetSpec], input_resolution: funlib.geometry.Coordinate, output_resolution: funlib.geometry.Coordinate, targets: Optional[List[str]] = None, segmentation_type: Union[str, SegmentationType] = 'semantic', max_gt_downsample=32, max_gt_upsample=4, max_raw_training_downsample=16, max_raw_training_upsample=2, max_raw_validation_downsample=8, max_raw_validation_upsample=2, min_training_volume_size=8000, raw_min=0, raw_max=255)


   Generates DataSplitConfig for a given task config and datasets.
   class names in gt_dataset shoulb be within [] e.g. [mito&peroxisome&er] for mutiple classes or [mito] for one class
   Currently only supports:
    - semantic segmentation.
    Supports:
       - 2D and 3D datasets.
       - Zarr, N5 and OME-Zarr datasets.
       - Multi class targets.

   .. py:property:: class_name


   .. py:method:: check_class_name(class_name)


   .. py:method:: compute()


   .. py:method:: generate_from_csv(csv_path: pathlib.Path, input_resolution: funlib.geometry.Coordinate, output_resolution: funlib.geometry.Coordinate, name: Optional[str] = None, **kwargs)
      :staticmethod:



