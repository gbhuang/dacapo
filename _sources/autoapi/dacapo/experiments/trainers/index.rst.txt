:py:mod:`dacapo.experiments.trainers`
=====================================

.. py:module:: dacapo.experiments.trainers


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   gp_augments/index.rst
   optimizers/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   dummy_trainer/index.rst
   dummy_trainer_config/index.rst
   gunpowder_trainer/index.rst
   gunpowder_trainer_config/index.rst
   trainer/index.rst
   trainer_config/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   dacapo.experiments.trainers.Trainer
   dacapo.experiments.trainers.TrainerConfig
   dacapo.experiments.trainers.DummyTrainerConfig
   dacapo.experiments.trainers.DummyTrainer
   dacapo.experiments.trainers.GunpowderTrainerConfig
   dacapo.experiments.trainers.GunpowderTrainer
   dacapo.experiments.trainers.AugmentConfig




.. py:class:: Trainer




   Trainer Abstract Base Class

   This serves as the blueprint for any trainer classes in the dacapo library.
   It defines essential methods that every subclass must implement for effective
   training of a neural network model.

   .. py:attribute:: iteration
      :type: int

      

   .. py:attribute:: batch_size
      :type: int

      

   .. py:attribute:: learning_rate
      :type: float

      

   .. py:method:: create_optimizer(model: dacapo.experiments.model.Model) -> torch.optim.Optimizer
      :abstractmethod:

      Creates an optimizer for the model.

      :param model: The model for which the optimizer will be created.
      :type model: Model

      :returns: The optimizer created for the model.
      :rtype: torch.optim.Optimizer


   .. py:method:: iterate(num_iterations: int, model: dacapo.experiments.model.Model, optimizer: torch.optim.Optimizer, device: torch.device) -> Iterator[dacapo.experiments.training_iteration_stats.TrainingIterationStats]
      :abstractmethod:

      Performs a number of training iterations.

      :param num_iterations: Number of training iterations.
      :type num_iterations: int
      :param model: The model to be trained.
      :type model: Model
      :param optimizer: The optimizer for the model.
      :type optimizer: torch.optim.Optimizer
      :param device: The device (GPU/CPU) where the model will be trained.
      :type device: torch.device

      :returns: An iterator of the training statistics.
      :rtype: Iterator[TrainingIterationStats]


   .. py:method:: can_train(datasets: List[dacapo.experiments.datasplits.datasets.Dataset]) -> bool
      :abstractmethod:

      Checks if the trainer can train with a specific set of datasets.

      Some trainers may have specific requirements for their training datasets.

      :param datasets: The training datasets.
      :type datasets: List[Dataset]

      :returns: True if the trainer can train on the given datasets, False otherwise.
      :rtype: bool


   .. py:method:: build_batch_provider(datasets: List[dacapo.experiments.datasplits.datasets.Dataset], model: dacapo.experiments.model.Model, task: dacapo.experiments.tasks.task.Task, snapshot_container: dacapo.store.array_store.LocalContainerIdentifier) -> None
      :abstractmethod:

      Initializes the training pipeline using various components.

      This method uses the datasets, model, task, and snapshot_container to set up the
      training pipeline.

      :param datasets: The datasets to pull data from.
      :type datasets: List[Dataset]
      :param model: The model to inform the pipeline of required input/output sizes.
      :type model: Model
      :param task: The task to transform ground truth into target.
      :type task: Task
      :param snapshot_container: Defines where snapshots will be saved.
      :type snapshot_container: LocalContainerIdentifier



.. py:class:: TrainerConfig


   A class to represent the Trainer Configurations.

   It is the base class for trainer configurations. Each subclass of a `Trainer`
   should have a specific config class derived from `TrainerConfig`.

   .. attribute:: name

      A unique name for this trainer.

      :type: str

   .. attribute:: batch_size

      The batch size to be used during training.

      :type: int

   .. attribute:: learning_rate

      The learning rate of the optimizer.

      :type: float

   .. py:attribute:: name
      :type: str

      

   .. py:attribute:: batch_size
      :type: int

      

   .. py:attribute:: learning_rate
      :type: float

      

   .. py:method:: verify() -> Tuple[bool, str]

      Verify whether this TrainerConfig is valid or not.

      :returns: A tuple containing a boolean indicating whether the
                TrainerConfig is valid and a message explaining why.
      :rtype: tuple



.. py:class:: DummyTrainerConfig




   This is just a dummy trainer config used for testing. None of the
   attributes have any particular meaning.

   .. py:attribute:: trainer_type

      

   .. py:attribute:: mirror_augment
      :type: bool

      

   .. py:method:: verify() -> Tuple[bool, str]

      Verify whether this TrainerConfig is valid or not.

      :returns: A tuple containing a boolean indicating whether the
                TrainerConfig is valid and a message explaining why.
      :rtype: tuple



.. py:class:: DummyTrainer(trainer_config)




   Trainer Abstract Base Class

   This serves as the blueprint for any trainer classes in the dacapo library.
   It defines essential methods that every subclass must implement for effective
   training of a neural network model.

   .. py:attribute:: iteration
      :value: 0

      

   .. py:method:: create_optimizer(model)

      Creates an optimizer for the model.

      :param model: The model for which the optimizer will be created.
      :type model: Model

      :returns: The optimizer created for the model.
      :rtype: torch.optim.Optimizer


   .. py:method:: iterate(num_iterations: int, model: dacapo.experiments.model.Model, optimizer, device)

      Performs a number of training iterations.

      :param num_iterations: Number of training iterations.
      :type num_iterations: int
      :param model: The model to be trained.
      :type model: Model
      :param optimizer: The optimizer for the model.
      :type optimizer: torch.optim.Optimizer
      :param device: The device (GPU/CPU) where the model will be trained.
      :type device: torch.device

      :returns: An iterator of the training statistics.
      :rtype: Iterator[TrainingIterationStats]


   .. py:method:: build_batch_provider(datasplit, architecture, task, snapshot_container)

      Initializes the training pipeline using various components.

      This method uses the datasets, model, task, and snapshot_container to set up the
      training pipeline.

      :param datasets: The datasets to pull data from.
      :type datasets: List[Dataset]
      :param model: The model to inform the pipeline of required input/output sizes.
      :type model: Model
      :param task: The task to transform ground truth into target.
      :type task: Task
      :param snapshot_container: Defines where snapshots will be saved.
      :type snapshot_container: LocalContainerIdentifier


   .. py:method:: can_train(datasplit)

      Checks if the trainer can train with a specific set of datasets.

      Some trainers may have specific requirements for their training datasets.

      :param datasets: The training datasets.
      :type datasets: List[Dataset]

      :returns: True if the trainer can train on the given datasets, False otherwise.
      :rtype: bool



.. py:class:: GunpowderTrainerConfig




   This class is used to configure a Gunpowder Trainer. It contains attributes related to trainer type,
   number of data fetchers, augmentations to apply, snapshot interval, minimum masked value, and a boolean
   value indicating whether to clip raw or not.

   .. attribute:: trainer_type

      This is the type of the trainer which is set to GunpowderTrainer by default.

      :type: class

   .. attribute:: num_data_fetchers

      This is the number of CPU workers who will be dedicated to fetch and process the data.

      :type: int

   .. attribute:: augments

      This is the list of augments to apply during the training.

      :type: List[AugmentConfig]

   .. attribute:: snapshot_interval

      This is the number of iterations after which a new snapshot should be saved.

      :type: Optional[int]

   .. attribute:: min_masked

      This is the minimum masked value.

      :type: Optional[float]

   .. attribute:: clip_raw

      This is a boolean value indicating if the raw data should be clipped to the size of the GT data or not.

      :type: bool

   .. py:attribute:: trainer_type

      

   .. py:attribute:: num_data_fetchers
      :type: int

      

   .. py:attribute:: augments
      :type: List[dacapo.experiments.trainers.gp_augments.AugmentConfig]

      

   .. py:attribute:: snapshot_interval
      :type: Optional[int]

      

   .. py:attribute:: min_masked
      :type: Optional[float]

      

   .. py:attribute:: clip_raw
      :type: bool

      


.. py:class:: GunpowderTrainer(trainer_config)




   Trainer Abstract Base Class

   This serves as the blueprint for any trainer classes in the dacapo library.
   It defines essential methods that every subclass must implement for effective
   training of a neural network model.

   .. py:attribute:: iteration
      :value: 0

      

   .. py:method:: create_optimizer(model)

      Creates an optimizer for the model.

      :param model: The model for which the optimizer will be created.
      :type model: Model

      :returns: The optimizer created for the model.
      :rtype: torch.optim.Optimizer


   .. py:method:: build_batch_provider(datasets, model, task, snapshot_container=None)

      Initializes the training pipeline using various components.

      This method uses the datasets, model, task, and snapshot_container to set up the
      training pipeline.

      :param datasets: The datasets to pull data from.
      :type datasets: List[Dataset]
      :param model: The model to inform the pipeline of required input/output sizes.
      :type model: Model
      :param task: The task to transform ground truth into target.
      :type task: Task
      :param snapshot_container: Defines where snapshots will be saved.
      :type snapshot_container: LocalContainerIdentifier


   .. py:method:: iterate(num_iterations, model, optimizer, device)

      Performs a number of training iterations.

      :param num_iterations: Number of training iterations.
      :type num_iterations: int
      :param model: The model to be trained.
      :type model: Model
      :param optimizer: The optimizer for the model.
      :type optimizer: torch.optim.Optimizer
      :param device: The device (GPU/CPU) where the model will be trained.
      :type device: torch.device

      :returns: An iterator of the training statistics.
      :rtype: Iterator[TrainingIterationStats]


   .. py:method:: next()


   .. py:method:: can_train(datasets) -> bool

      Checks if the trainer can train with a specific set of datasets.

      Some trainers may have specific requirements for their training datasets.

      :param datasets: The training datasets.
      :type datasets: List[Dataset]

      :returns: True if the trainer can train on the given datasets, False otherwise.
      :rtype: bool



.. py:class:: AugmentConfig




   Base class for gunpowder augment configurations. Each subclass of a `Augment`
   should have a corresponding config class derived from `AugmentConfig`.

   .. py:method:: node(raw_key: gunpowder.ArrayKey, gt_key: gunpowder.ArrayKey, mask_key: gunpowder.ArrayKey) -> gunpowder.BatchFilter
      :abstractmethod:

      return a gunpowder node that performs this augmentation



