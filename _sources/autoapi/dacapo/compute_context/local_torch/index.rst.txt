:py:mod:`dacapo.compute_context.local_torch`
============================================

.. py:module:: dacapo.compute_context.local_torch

.. autoapi-nested-parse::

   This module provides the LocalTorch class which is used to determine and set the local torch device (CPU or GPU) for
   computation. This information can be particularly useful for deep learning computations where use of GPU can
   significantly speed up computations.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   dacapo.compute_context.local_torch.LocalTorch




.. py:class:: LocalTorch




   The LocalTorch class is a subclass of the ComputeContext class. It is decorated with the attrs library, which
   provides a convenient way of structuring data. It focuses on determining the type of device on which torch
   computations will be done. It defaults to GPU (if available) over CPU.

   .. attribute:: _device

      This stores the type of device on which torch computations are to be done. It can

      :type: Optional[str]

   .. attribute:: take "cuda" for GPU or "cpu" for CPU. None value results in automatic detection of device type.

      

   .. py:property:: device

      A property method that returns the torch device object. It automatically detects and uses "cuda" (GPU) if
      available, else it falls back on using "cpu".


