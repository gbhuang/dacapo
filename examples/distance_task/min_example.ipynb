{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dacapo\n",
    "\n",
    "DaCapo is a framework that allows for easy configuration and execution of established machine learning techniques on arbitrarily large volumes of multi-dimensional images.\n",
    "\n",
    "DaCapo has 4 major configurable components:\n",
    "1. **dacapo.datasplits.DataSplit**\n",
    "\n",
    "2. **dacapo.tasks.Task**\n",
    "\n",
    "3. **dacapo.architectures.Architecture**\n",
    "\n",
    "4. **dacapo.trainers.Trainer**\n",
    "\n",
    "These are then combined in a single **dacapo.experiments.Run** that includes your starting point (whether you want to start training from scratch or continue off of a previously trained model) and stopping criterion (the number of iterations you want to train)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "If you have not already done so, you will need to install DaCapo. You can do this by first creating a new environment and then installing DaCapo using pip.\n",
    "\n",
    "```bash\n",
    "conda create -n dacapo python=3.10\n",
    "conda activate dacapo\n",
    "```\n",
    "\n",
    "Then, you can install DaCapo using pip, via GitHub:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/janelia-cellmap/dacapo.git\n",
    "```\n",
    "\n",
    "Or you can clone the repository and install it locally:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/janelia-cellmap/dacapo.git\n",
    "cd dacapo\n",
    "pip install -e .\n",
    "```\n",
    "\n",
    "Be sure to select this environment in your Jupyter notebook or JupyterLab."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasplit\n",
    "Where can you find your data? What format is it in? Does it need to be normalized? What data do you want to use for validation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo import DataConfig\n",
    "data_config = DataConfig(\n",
    "    # optional name\n",
    "    datasets = [\n",
    "        {\"role\": \"train\", \"raw\": \"dsb_nuclei.zarr/train/raw\", \"gt\": \"dsb_nuclei.zarr/train/gt\"},\n",
    "        {\"role\": \"validate\", \"raw\": \"dsb_nuclei.zarr/validate/raw\", \"gt\": \"dsb_nuclei.zarr/validate/gt\"},\n",
    "    ]\n",
    "    # gets store in init and stores itself\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "What do you want to learn? An instance segmentation? If so, how? Affinities,\n",
    "Distance Transform, Foreground/Background, etc. Each of these tasks are commonly learned\n",
    "and evaluated with specific loss functions and evaluation metrics. Some tasks may\n",
    "also require specific non-linearities or output formats from your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacapo import TaskConfig\n",
    "\n",
    "task_config = TaskConfig(\n",
    "    target=\"semantic\",\n",
    "    classes=2, # overwrites num_classes from zarr metadata, otherwise inferred from metadata\n",
    "    # optional dict mapping label ids to names\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "The setup of the network you will train. Biomedical image to image translation often utilizes a UNet, but even after choosing a UNet you still need to provide some additional parameters. How much do you want to downsample? How many convolutional layers do you want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "# from dacapo import ArchitectureConfig\n",
    "\n",
    "# architecture_config = ArchitectureConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n",
    "\n",
    "How do you want to train? This config defines the training loop and how the other three components work together. What sort of augmentations to apply during training, what learning rate and optimizer to use, what batch size to train with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "# from dacapo import TrainerConfig\n",
    "\n",
    "# trainer_config = TrainerConfig()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run\n",
    "Now that we have our components configured, we just need to combine them into a run and start training. We can have multiple repetitions of a single set of configs in order to increase our chances of finding an optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_finetuned_example_jrc_mus-livers_peroxisome_8nm_example_distances_8nm_peroxisome_example_attention-upsample-unet_example_default_one_label_finetuning__0\n",
      "example_finetuned_example_jrc_mus-livers_peroxisome_8nm_example_distances_8nm_peroxisome_example_attention-upsample-unet_example_default_one_label_finetuning__1\n",
      "example_finetuned_example_jrc_mus-livers_peroxisome_8nm_example_distances_8nm_peroxisome_example_attention-upsample-unet_example_default_one_label_finetuning__2\n"
     ]
    }
   ],
   "source": [
    "# optional\n",
    "# from dacapo import StartConfig\n",
    "\n",
    "# start_config = StartConfig(\n",
    "#     \"setup04\",\n",
    "#     \"best\",\n",
    "# )\n",
    "\n",
    "from dacapo import Experiment\n",
    "\n",
    "experiment = Experiment(\n",
    "    name=\"dsb_nuclei\", # complain if not unique, allow overwrite, allow load from name\n",
    "    data_config,\n",
    "    task_config,\n",
    "    # architecture_config,\n",
    "    # trainer_config,\n",
    "    # start_config,\n",
    "    num_iterations=200000,\n",
    "    # num_repetitions=1,\n",
    "    # validation_interval=5000,\n",
    "    # overwrite=False, # set to true to overwrite any previous experiment with the same name ( data and models included )\n",
    ")\n",
    "# experiment = Experiment.load(\"dsb_nuclei\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train one of the runs, you can either do it by first creating a **Run** directly from the run config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.run() # allow run in compute context, if need to continue do so, if done report\n",
    "\n",
    "# or experiment.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to start your run on some compute cluster, you might want to use the command line interface: dacapo train -r {run_config.name}. This makes it particularly convenient to run on compute nodes where you can specify specific compute requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply\n",
    "\n",
    "Once you have trained your model, you can use it to make predictions on new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = experiment.get_model(\n",
    "    # criterion=task.default_criterion(),\n",
    "    # validation_dataset=data.get_datasets(\"validate\"),\n",
    ")\n",
    "\n",
    "# dacapo.predict(model, \"dsb_nuclei.zarr/test/raw\", \"dsb_nuclei.zarr/test/pred\" # doesn't post-process\n",
    "\n",
    "dacapo.apply(model, input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plasmodesmata_dacapo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
